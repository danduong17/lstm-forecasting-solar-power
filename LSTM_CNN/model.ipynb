{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(0, 339, None), slice(None, None, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Nhan Duong\\anaconda3\\envs\\new_kera_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Nhan Duong\\anaconda3\\envs\\new_kera_env\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Nhan Duong\\anaconda3\\envs\\new_kera_env\\lib\\site-packages\\pandas\\_libs\\index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(0, 339, None), slice(None, None, None))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m train_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(data) \u001b[39m*\u001b[39m \u001b[39m0.7\u001b[39m)\n\u001b[0;32m     36\u001b[0m test_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data) \u001b[39m-\u001b[39m train_size\n\u001b[1;32m---> 37\u001b[0m train_data, test_data \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39;49m:train_size,:], data[train_size:\u001b[39mlen\u001b[39m(data),:]\n\u001b[0;32m     39\u001b[0m X_train, y_train \u001b[39m=\u001b[39m train_data[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], train_data[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     40\u001b[0m X_test, y_test \u001b[39m=\u001b[39m test_data[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], test_data[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Nhan Duong\\anaconda3\\envs\\new_kera_env\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Nhan Duong\\anaconda3\\envs\\new_kera_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3804\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m         \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m         \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m         \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3809\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing_error(key)\n\u001b[0;32m   3810\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m \u001b[39m# GH#42269\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nhan Duong\\anaconda3\\envs\\new_kera_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5925\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5921\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_indexing_error\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m   5922\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5923\u001b[0m         \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5924\u001b[0m         \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5925\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(0, 339, None), slice(None, None, None))"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the data from Excel\n",
    "data = pd.read_excel('../data/Data_for_ML_TT-DB0.xlsx', sheet_name=\"Data\", header=0, usecols=[1])\n",
    "# data_feature = pd.read_excel('../data/Data_for_ML_TT-DB0.xlsx', header=0, usecols='A:B')\n",
    "data_target = pd.read_excel('../data/Data_for_ML_TT-DB0.xlsx', header=0, usecols='C')\n",
    "\n",
    "# Data preprocessing\n",
    "# Assuming you have already preprocessed the data and included relevant features in X.\n",
    "# X should be a 3D array (samples, time steps, features) for LSTM-CNN model.\n",
    "# In this case, extract the features and target variable (LC)\n",
    "X = data.values\n",
    "y = data_target.values\n",
    "\n",
    "\n",
    "# Define the look-back window (number of time steps to consider for prediction)\n",
    "look_back = 12\n",
    "\n",
    "# Convert the data into sequences\n",
    "X = []\n",
    "for i in range(len(data) - look_back):\n",
    "    X.append(data.iloc[i:i+look_back].values)\n",
    "X = np.array(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_size = int(len(data) * 0.7)\n",
    "test_size = len(data) - train_size\n",
    "train_data, test_data = data[0:train_size,:], data[train_size:len(data),:]\n",
    "\n",
    "X_train, y_train = train_data[:, :-1], train_data[:, -1]\n",
    "X_test, y_test = test_data[:, :-1], test_data[:, -1]\n",
    "\n",
    "# Reshape data to fit the LSTM-CNN model input requirements\n",
    "# The LSTM-CNN model expects data in the format of (samples, time steps, features)\n",
    "# Here, we assume time steps (look_back) is 1 for simplicity, as we are only using the current data point.\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "\n",
    "# Build the LSTM-CNN model\n",
    "model = Sequential()\n",
    "# model.add(Conv1D(filters=64, kernel_size=3, activation=\"relu\", input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation=\"relu\", input_shape=(look_back, X_train.shape[1])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(50, activation=\"relu\"))\n",
    "model.add(Dense(1))  # Output layer with 1 neuron for regression\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Make predictions\n",
    "# y_pred = model.predict(X_test)\n",
    "train_predictions = model.predict(X_train)\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values to their original scale\n",
    "# y_pred_original = scaler.inverse_transform(y_pred).flatten()\n",
    "# y_test_original = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "train_predictions_original = scaler.inverse_transform(X_train).flatten()\n",
    "test_predictions_original = scaler.inverse_transform(X_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Training predictions:\", train_predictions_original)\n",
    "print(\"Testing predictions:\", test_predictions_original)\n",
    "\n",
    "# Calculate the accuracy metrics (e.g., Mean Squared Error, Mean Absolute Error, R-squared)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# mse = mean_squared_error(y_test_original, y_pred_original)\n",
    "# mae = mean_absolute_error(y_test_original, y_pred_original)\n",
    "# r2 = r2_score(y_test_original, y_pred_original)\n",
    "mse = mean_squared_error(test_predictions_original, train_predictions_original)\n",
    "mae = mean_absolute_error(test_predictions_original, train_predictions_original)\n",
    "r2 = r2_score(test_predictions_original, train_predictions_original)\n",
    "\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_kera_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
